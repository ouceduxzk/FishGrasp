#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å¤šç±»åˆ«æ£€æµ‹é…ç½®æµ‹è¯•è„šæœ¬

æµ‹è¯•å¤šç±»åˆ«æ£€æµ‹çš„é…ç½®å’ŒåŠŸèƒ½
"""

import sys
import os
import yaml
from pathlib import Path

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

def test_dataset_config():
    """æµ‹è¯•æ•°æ®é›†é…ç½®"""
    print("ðŸ”§ æµ‹è¯•æ•°æ®é›†é…ç½®")
    print("="*50)
    
    # æ£€æŸ¥æ•°æ®é›†YAMLæ–‡ä»¶
    dataset_yaml = Path("datasets/l0_9.12/dataset.yaml")
    
    if not dataset_yaml.exists():
        print(f"âŒ æ•°æ®é›†é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_yaml}")
        return False
    
    # è¯»å–é…ç½®
    with open(dataset_yaml, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    print(f"âœ… æ•°æ®é›†é…ç½®åŠ è½½æˆåŠŸ")
    print(f"   è·¯å¾„: {config['path']}")
    print(f"   è®­ç»ƒé›†: {config['train']}")
    print(f"   éªŒè¯é›†: {config['val']}")
    print(f"   æµ‹è¯•é›†: {config['test']}")
    print(f"   ç±»åˆ«: {config['names']}")
    
    # éªŒè¯ç±»åˆ«é…ç½®
    expected_classes = ['èƒŒæ™¯', 'é±¿é±¼']
    if config['names'] == expected_classes:
        print("âœ… ç±»åˆ«é…ç½®æ­£ç¡®")
        print(f"   ç±»åˆ«0: {config['names'][0]} (èƒŒæ™¯)")
        print(f"   ç±»åˆ«1: {config['names'][1]} (é±¿é±¼)")
    else:
        print("âŒ ç±»åˆ«é…ç½®ä¸æ­£ç¡®")
        print(f"   æœŸæœ›: {expected_classes}")
        print(f"   å®žé™…: {config['names']}")
        return False
    
    return True

def test_class_distribution():
    """æµ‹è¯•ç±»åˆ«åˆ†å¸ƒ"""
    print("\nðŸ”§ æµ‹è¯•ç±»åˆ«åˆ†å¸ƒ")
    print("="*50)
    
    dataset_path = Path("datasets/l0_9.12")
    train_labels = dataset_path / "labels" / "train"
    val_labels = dataset_path / "labels" / "val"
    
    if not train_labels.exists() or not val_labels.exists():
        print("âŒ æ ‡ç­¾ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    class_counts = {0: 0, 1: 0}  # èƒŒæ™¯, é±¿é±¼
    total_files = 0
    
    for split_name, split_path in [("è®­ç»ƒé›†", train_labels), ("éªŒè¯é›†", val_labels)]:
        split_counts = {0: 0, 1: 0}
        split_files = 0
        
        for label_file in split_path.glob("*.txt"):
            split_files += 1
            with open(label_file, 'r') as f:
                for line in f:
                    line = line.strip()
                    if line:
                        try:
                            class_id = int(line.split()[0])
                            if class_id in [0, 1]:
                                split_counts[class_id] += 1
                                class_counts[class_id] += 1
                        except (ValueError, IndexError):
                            continue
        
        total_files += split_files
        print(f"{split_name}:")
        print(f"   æ–‡ä»¶æ•°: {split_files}")
        print(f"   èƒŒæ™¯å®žä¾‹: {split_counts[0]}")
        print(f"   é±¿é±¼å®žä¾‹: {split_counts[1]}")
        print(f"   æ€»è®¡å®žä¾‹: {sum(split_counts.values())}")
    
    print(f"\næ€»ä½“ç»Ÿè®¡:")
    print(f"   æ€»æ–‡ä»¶æ•°: {total_files}")
    print(f"   èƒŒæ™¯å®žä¾‹: {class_counts[0]}")
    print(f"   é±¿é±¼å®žä¾‹: {class_counts[1]}")
    print(f"   æ€»è®¡å®žä¾‹: {sum(class_counts.values())}")
    
    # æ£€æŸ¥ç±»åˆ«å¹³è¡¡æ€§
    if class_counts[0] > 0 and class_counts[1] > 0:
        ratio = class_counts[1] / class_counts[0]
        print(f"   ç±»åˆ«æ¯”ä¾‹ (é±¿é±¼/èƒŒæ™¯): {ratio:.3f}")
        
        if 0.1 <= ratio <= 10.0:
            print("âœ… ç±»åˆ«åˆ†å¸ƒç›¸å¯¹å¹³è¡¡")
        else:
            print("âš ï¸  ç±»åˆ«åˆ†å¸ƒä¸å¹³è¡¡ï¼Œå»ºè®®è°ƒæ•´")
    else:
        print("âŒ æŸä¸ªç±»åˆ«æ²¡æœ‰å®žä¾‹")
        return False
    
    return True

def test_hard_negative_mining():
    """æµ‹è¯•ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜"""
    print("\nðŸ”§ æµ‹è¯•ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜")
    print("="*50)
    
    try:
        from hard_negative_mining import HardNegativeMiner
    except ImportError as e:
        print(f"âŒ å¯¼å…¥å¤±è´¥: {e}")
        return False
    
    # åˆ›å»ºæŒ–æŽ˜å™¨
    miner = HardNegativeMiner(
        confidence_threshold=0.5,
        iou_threshold=0.5,
        save_samples=False
    )
    
    # æ¨¡æ‹Ÿå¤šç±»åˆ«é¢„æµ‹ç»“æžœ
    predictions = [
        {'bbox': [100, 100, 200, 200], 'confidence': 0.8, 'class': 1},  # é«˜ç½®ä¿¡åº¦é±¿é±¼
        {'bbox': [300, 300, 400, 400], 'confidence': 0.3, 'class': 0},  # ä½Žç½®ä¿¡åº¦èƒŒæ™¯
        {'bbox': [500, 500, 600, 600], 'confidence': 0.9, 'class': 1},  # é«˜ç½®ä¿¡åº¦é±¿é±¼
        {'bbox': [700, 700, 800, 800], 'confidence': 0.7, 'class': 0}   # ä¸­ç­‰ç½®ä¿¡åº¦èƒŒæ™¯
    ]
    
    # æ¨¡æ‹Ÿå¤šç±»åˆ«çœŸå®žæ ‡æ³¨
    ground_truth = [
        {'bbox': [110, 110, 210, 210], 'class': 1},  # é±¿é±¼
        {'bbox': [520, 520, 620, 620], 'class': 1},  # é±¿é±¼
        {'bbox': [150, 150, 250, 250], 'class': 0}   # èƒŒæ™¯
    ]
    
    # è¿›è¡Œç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜
    hard_negatives = miner.find_hard_negatives(predictions, ground_truth)
    
    print(f"âœ… ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜å®Œæˆ")
    print(f"   æ‰¾åˆ° {len(hard_negatives)} ä¸ªç¡¬è´Ÿæ ·æœ¬")
    
    # æŒ‰ç±»åˆ«åˆ†æžç¡¬è´Ÿæ ·æœ¬
    background_hard = [hn for hn in hard_negatives if hn['prediction']['class'] == 0]
    squid_hard = [hn for hn in hard_negatives if hn['prediction']['class'] == 1]
    
    print(f"   èƒŒæ™¯å›°éš¾æ ·æœ¬: {len(background_hard)}")
    print(f"   é±¿é±¼å›°éš¾æ ·æœ¬: {len(squid_hard)}")
    
    # æ‰“å°è¯¦ç»†ä¿¡æ¯
    for i, hn in enumerate(hard_negatives):
        class_name = "èƒŒæ™¯" if hn['prediction']['class'] == 0 else "é±¿é±¼"
        print(f"   {i+1}. {class_name} - ç±»åž‹: {hn['type']}, ç½®ä¿¡åº¦: {hn['confidence']:.3f}, IoU: {hn['iou']:.3f}")
    
    return True

def test_training_commands():
    """æµ‹è¯•è®­ç»ƒå‘½ä»¤"""
    print("\nðŸ”§ æµ‹è¯•è®­ç»ƒå‘½ä»¤")
    print("="*50)
    
    commands = [
        {
            "name": "åŸºæœ¬å¤šç±»åˆ«è®­ç»ƒ",
            "command": """python3 detection/train_yolo.py \\
    --data ./datasets/l0_9.12/dataset.yaml \\
    --model yolov8s.pt \\
    --epochs 100 \\
    --project runs/train \\
    --name multi_class_squid_background_$(date +%Y%m%d_%H%M%S)"""
        },
        {
            "name": "ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜è®­ç»ƒ",
            "command": """python3 detection/train_yolo_with_hard_negative.py \\
    --data ./datasets/l0_9.12/dataset.yaml \\
    --model yolov8s.pt \\
    --epochs 100 \\
    --project runs/train \\
    --name multi_class_hard_negative_$(date +%Y%m%d_%H%M%S) \\
    --mining_strategy confidence_based \\
    --hard_negative_ratio 0.3"""
        },
        {
            "name": "ä½¿ç”¨é¢„è®­ç»ƒæ¨¡åž‹",
            "command": """python3 detection/train_yolo_with_hard_negative.py \\
    --data ./datasets/l0_9.12/dataset.yaml \\
    --model yolov8s.pt \\
    --epochs 100 \\
    --use_pretrained_for_mining \\
    --mining_strategy confidence_based"""
        }
    ]
    
    for i, cmd in enumerate(commands, 1):
        print(f"å‘½ä»¤ {i}: {cmd['name']}")
        print(cmd['command'])
        print()
    
    print("âœ… è®­ç»ƒå‘½ä»¤é…ç½®å®Œæˆ")
    return True

def test_performance_analysis():
    """æµ‹è¯•æ€§èƒ½åˆ†æž"""
    print("\nðŸ”§ æµ‹è¯•æ€§èƒ½åˆ†æž")
    print("="*50)
    
    # æ¨¡æ‹Ÿè®­ç»ƒç»“æžœ
    mock_results = {
        'overall': {
            'precision': 0.944,
            'recall': 0.972,
            'mAP50': 0.977,
            'mAP50-95': 0.722
        },
        'background': {
            'precision': 0.950,
            'recall': 0.980,
            'mAP50': 0.985,
            'mAP50-95': 0.750
        },
        'squid': {
            'precision': 0.938,
            'recall': 0.964,
            'mAP50': 0.969,
            'mAP50-95': 0.694
        }
    }
    
    print("æ¨¡æ‹Ÿè®­ç»ƒç»“æžœåˆ†æž:")
    print("="*30)
    
    for class_name, metrics in mock_results.items():
        print(f"{class_name.upper()}:")
        print(f"  ç²¾ç¡®çŽ‡: {metrics['precision']:.3f}")
        print(f"  å¬å›žçŽ‡: {metrics['recall']:.3f}")
        print(f"  mAP50: {metrics['mAP50']:.3f}")
        print(f"  mAP50-95: {metrics['mAP50-95']:.3f}")
        print()
    
    # åˆ†æžç±»åˆ«æ€§èƒ½å·®å¼‚
    background_map50 = mock_results['background']['mAP50']
    squid_map50 = mock_results['squid']['mAP50']
    performance_gap = abs(background_map50 - squid_map50)
    
    print("æ€§èƒ½åˆ†æž:")
    print(f"  èƒŒæ™¯ mAP50: {background_map50:.3f}")
    print(f"  é±¿é±¼ mAP50: {squid_map50:.3f}")
    print(f"  æ€§èƒ½å·®è·: {performance_gap:.3f}")
    
    if performance_gap < 0.05:
        print("âœ… ç±»åˆ«æ€§èƒ½å¹³è¡¡")
    else:
        print("âš ï¸  ç±»åˆ«æ€§èƒ½ä¸å¹³è¡¡ï¼Œå»ºè®®è°ƒæ•´")
    
    return True

def main():
    """ä¸»å‡½æ•°"""
    print("ðŸš€ å¤šç±»åˆ«æ£€æµ‹é…ç½®æµ‹è¯•")
    print("="*60)
    
    success_count = 0
    total_tests = 5
    
    # è¿è¡Œæµ‹è¯•
    if test_dataset_config():
        success_count += 1
    
    if test_class_distribution():
        success_count += 1
    
    if test_hard_negative_mining():
        success_count += 1
    
    if test_training_commands():
        success_count += 1
    
    if test_performance_analysis():
        success_count += 1
    
    # è¾“å‡ºæµ‹è¯•ç»“æžœ
    print("\n" + "="*60)
    print("ðŸ“Š æµ‹è¯•ç»“æžœæ‘˜è¦")
    print("="*60)
    print(f"é€šè¿‡æµ‹è¯•: {success_count}/{total_tests}")
    
    if success_count == total_tests:
        print("ðŸŽ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å¤šç±»åˆ«æ£€æµ‹é…ç½®æ­£ç¡®")
        print("\nðŸ“ ä½¿ç”¨å»ºè®®:")
        print("1. ä½¿ç”¨æ›´æ–°åŽçš„æ•°æ®é›†é…ç½®è¿›è¡Œè®­ç»ƒ")
        print("2. ç›‘æŽ§æ¯ä¸ªç±»åˆ«çš„æ€§èƒ½æŒ‡æ ‡")
        print("3. ä½¿ç”¨ç¡¬è´Ÿæ ·æœ¬æŒ–æŽ˜æé«˜æ€§èƒ½")
        print("4. æ ¹æ®ç±»åˆ«å¹³è¡¡æ€§è°ƒæ•´è®­ç»ƒç­–ç•¥")
        print("5. åˆ†æžç±»åˆ«é—´çš„æ··æ·†æƒ…å†µ")
    else:
        print("âŒ éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®")
    
    return success_count == total_tests

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1)


