#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å°†é±¼ä½“å…³é”®ç‚¹æ£€æµ‹é›†æˆåˆ°ä¸»ç³»ç»Ÿä¸­

è¿™ä¸ªè„šæœ¬å±•ç¤ºäº†å¦‚ä½•å°†å…³é”®ç‚¹æ£€æµ‹é›†æˆåˆ°ä½ çš„å®æ—¶åˆ†å‰²å’ŒæŠ“å–ç³»ç»Ÿä¸­
"""

import sys
import os
import numpy as np
import cv2
import time
from typing import Optional, Tuple, Dict, Any

# æ·»åŠ å½“å‰ç›®å½•åˆ°Pythonè·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from realtime_landmark_detection import RealtimeFishLandmarkDetector


class EnhancedGraspSystem:
    """å¢å¼ºçš„æŠ“å–ç³»ç»Ÿï¼Œé›†æˆå…³é”®ç‚¹æ£€æµ‹"""
    
    def __init__(self, landmark_model_path: str, device: str = 'cuda'):
        """
        åˆå§‹åŒ–å¢å¼ºæŠ“å–ç³»ç»Ÿ
        
        Args:
            landmark_model_path: å…³é”®ç‚¹æ£€æµ‹æ¨¡å‹è·¯å¾„
            device: è®¡ç®—è®¾å¤‡
        """
        # åˆå§‹åŒ–å…³é”®ç‚¹æ£€æµ‹å™¨
        self.landmark_detector = RealtimeFishLandmarkDetector(
            model_path=landmark_model_path,
            device=device
        )
        
        # æŠ“å–ç­–ç•¥é…ç½®
        self.grasp_strategies = {
            'landmark_based': self._grasp_based_on_landmarks,
            'fallback_to_bbox': self._grasp_based_on_bbox,
            'hybrid': self._hybrid_grasp_strategy
        }
        
        self.current_strategy = 'hybrid'
        self.landmark_confidence_threshold = 0.7
        
        print("âœ… å¢å¼ºæŠ“å–ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
        print(f"   å…³é”®ç‚¹æ£€æµ‹å™¨: {landmark_model_path}")
        print(f"   æŠ“å–ç­–ç•¥: {self.current_strategy}")
    
    def detect_and_calculate_grasp_point(self, rgb_image: np.ndarray, 
                                        depth_image: np.ndarray,
                                        bbox: Optional[np.ndarray] = None) -> Tuple[np.ndarray, Dict[str, Any]]:
        """
        æ£€æµ‹å…³é”®ç‚¹å¹¶è®¡ç®—æŠ“å–ç‚¹
        
        Args:
            rgb_image: RGBå›¾åƒ
            depth_image: æ·±åº¦å›¾åƒ
            bbox: è¾¹ç•Œæ¡† (å¯é€‰ï¼Œä½œä¸ºå¤‡é€‰æ–¹æ¡ˆ)
            
        Returns:
            grasp_point: æŠ“å–ç‚¹åæ ‡ (2,)
            info: è¯¦ç»†ä¿¡æ¯
        """
        info = {
            'method': 'unknown',
            'confidence': 0.0,
            'landmark_detection_success': False,
            'bbox_available': bbox is not None,
            'processing_time': 0.0
        }
        
        start_time = time.time()
        
        try:
            # æ–¹æ³•1: åŸºäºå…³é”®ç‚¹çš„æŠ“å–
            if self.current_strategy in ['landmark_based', 'hybrid']:
                landmarks, visibility, landmark_info = self.landmark_detector.detect_landmarks(rgb_image)
                
                if landmarks is not None and len(landmarks) > 0:
                    # è®¡ç®—åŸºäºå…³é”®ç‚¹çš„æŠ“å–ç‚¹
                    grasp_point, grasp_info = self.landmark_detector.calculate_grasp_point(landmarks, visibility)
                    
                    # æ£€æŸ¥ç½®ä¿¡åº¦
                    if grasp_info['confidence'] >= self.landmark_confidence_threshold:
                        info.update({
                            'method': 'landmark_based',
                            'confidence': grasp_info['confidence'],
                            'landmark_detection_success': True,
                            'landmarks': landmarks.tolist(),
                            'visibility': visibility.tolist(),
                            'grasp_info': grasp_info
                        })
                        
                        processing_time = time.time() - start_time
                        info['processing_time'] = processing_time
                        
                        return grasp_point, info
            
            # æ–¹æ³•2: åŸºäºè¾¹ç•Œæ¡†çš„æŠ“å–ï¼ˆå¤‡é€‰æ–¹æ¡ˆï¼‰
            if self.current_strategy in ['fallback_to_bbox', 'hybrid'] and bbox is not None:
                # ä½¿ç”¨è¾¹ç•Œæ¡†ä¸­å¿ƒä½œä¸ºæŠ“å–ç‚¹
                x1, y1, x2, y2 = bbox
                grasp_point = np.array([(x1 + x2) / 2, (y1 + y2) / 2])
                
                info.update({
                    'method': 'bbox_fallback',
                    'confidence': 0.5,  # è¾¹ç•Œæ¡†æ–¹æ³•çš„å›ºå®šç½®ä¿¡åº¦
                    'bbox': bbox.tolist(),
                    'landmark_detection_success': False
                })
                
                processing_time = time.time() - start_time
                info['processing_time'] = processing_time
                
                return grasp_point, info
            
            # æ–¹æ³•3: é»˜è®¤æŠ“å–ç‚¹
            h, w = rgb_image.shape[:2]
            grasp_point = np.array([w // 2, h // 2])  # å›¾åƒä¸­å¿ƒ
            
            info.update({
                'method': 'default_center',
                'confidence': 0.1,
                'landmark_detection_success': False
            })
            
        except Exception as e:
            print(f"âš ï¸  æŠ“å–ç‚¹è®¡ç®—å‡ºé”™: {e}")
            h, w = rgb_image.shape[:2]
            grasp_point = np.array([w // 2, h // 2])
            info['error'] = str(e)
        
        processing_time = time.time() - start_time
        info['processing_time'] = processing_time
        
        return grasp_point, info
    
    def _grasp_based_on_landmarks(self, landmarks: np.ndarray, visibility: np.ndarray) -> np.ndarray:
        """åŸºäºå…³é”®ç‚¹çš„æŠ“å–ç­–ç•¥"""
        return self.landmark_detector.calculate_grasp_point(landmarks, visibility)[0]
    
    def _grasp_based_on_bbox(self, bbox: np.ndarray) -> np.ndarray:
        """åŸºäºè¾¹ç•Œæ¡†çš„æŠ“å–ç­–ç•¥"""
        x1, y1, x2, y2 = bbox
        return np.array([(x1 + x2) / 2, (y1 + y2) / 2])
    
    def _hybrid_grasp_strategy(self, landmarks: Optional[np.ndarray], 
                              visibility: Optional[np.ndarray], 
                              bbox: Optional[np.ndarray]) -> np.ndarray:
        """æ··åˆæŠ“å–ç­–ç•¥"""
        # ä¼˜å…ˆä½¿ç”¨å…³é”®ç‚¹ï¼Œå¦‚æœç½®ä¿¡åº¦ä¸å¤Ÿåˆ™ä½¿ç”¨è¾¹ç•Œæ¡†
        if landmarks is not None and len(landmarks) > 0:
            grasp_point, grasp_info = self.landmark_detector.calculate_grasp_point(landmarks, visibility)
            if grasp_info['confidence'] >= self.landmark_confidence_threshold:
                return grasp_point
        
        # å¤‡é€‰ï¼šä½¿ç”¨è¾¹ç•Œæ¡†
        if bbox is not None:
            return self._grasp_based_on_bbox(bbox)
        
        # æœ€åå¤‡é€‰ï¼šå›¾åƒä¸­å¿ƒ
        return np.array([0, 0])  # è¿™é‡Œåº”è¯¥ä¼ å…¥å›¾åƒå°ºå¯¸
    
    def visualize_enhanced_detection(self, rgb_image: np.ndarray, 
                                   grasp_point: np.ndarray, 
                                   info: Dict[str, Any],
                                   landmarks: Optional[np.ndarray] = None,
                                   visibility: Optional[np.ndarray] = None,
                                   bbox: Optional[np.ndarray] = None) -> np.ndarray:
        """å¯è§†åŒ–å¢å¼ºæ£€æµ‹ç»“æœ"""
        vis_image = rgb_image.copy()
        
        # ç»˜åˆ¶è¾¹ç•Œæ¡†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if bbox is not None:
            x1, y1, x2, y2 = bbox.astype(int)
            cv2.rectangle(vis_image, (x1, y1), (x2, y2), (0, 255, 255), 2)  # é»„è‰²è¾¹ç•Œæ¡†
            cv2.putText(vis_image, 'Detection Box', (x1, y1 - 10), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ç»˜åˆ¶å…³é”®ç‚¹ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if landmarks is not None and len(landmarks) > 0:
            vis_image = self.landmark_detector.visualize_detection(
                vis_image, landmarks, visibility, grasp_point, info
            )
        else:
            # åªç»˜åˆ¶æŠ“å–ç‚¹
            x, y = int(grasp_point[0]), int(grasp_point[1])
            cv2.circle(vis_image, (x, y), 15, (255, 0, 255), -1)  # ç´«è‰²å¤§åœ†
            cv2.circle(vis_image, (x, y), 20, (255, 255, 255), 3)  # ç™½è‰²è¾¹æ¡†
            cv2.putText(vis_image, 'GRASP', (x + 25, y + 5), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 255), 2)
        
        # æ·»åŠ æ–¹æ³•ä¿¡æ¯
        method = info.get('method', 'unknown')
        confidence = info.get('confidence', 0.0)
        
        cv2.putText(vis_image, f"Method: {method}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        cv2.putText(vis_image, f"Confidence: {confidence:.2f}", (10, 55), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        # æ·»åŠ å¤„ç†æ—¶é—´
        processing_time = info.get('processing_time', 0.0)
        cv2.putText(vis_image, f"Time: {processing_time*1000:.1f}ms", (10, 80), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
        
        return vis_image
    
    def set_grasp_strategy(self, strategy: str):
        """è®¾ç½®æŠ“å–ç­–ç•¥"""
        if strategy in self.grasp_strategies:
            self.current_strategy = strategy
            print(f"âœ… æŠ“å–ç­–ç•¥å·²è®¾ç½®ä¸º: {strategy}")
        else:
            print(f"âŒ æœªçŸ¥çš„æŠ“å–ç­–ç•¥: {strategy}")
            print(f"å¯ç”¨ç­–ç•¥: {list(self.grasp_strategies.keys())}")
    
    def set_confidence_threshold(self, threshold: float):
        """è®¾ç½®ç½®ä¿¡åº¦é˜ˆå€¼"""
        self.landmark_confidence_threshold = threshold
        print(f"âœ… ç½®ä¿¡åº¦é˜ˆå€¼å·²è®¾ç½®ä¸º: {threshold}")
    
    def get_performance_stats(self) -> Dict[str, Any]:
        """è·å–æ€§èƒ½ç»Ÿè®¡"""
        landmark_stats = self.landmark_detector.get_performance_stats()
        return {
            'landmark_detector': landmark_stats,
            'grasp_strategy': self.current_strategy,
            'confidence_threshold': self.landmark_confidence_threshold
        }


def create_integration_example():
    """åˆ›å»ºé›†æˆç¤ºä¾‹ä»£ç """
    
    example_code = '''
# åœ¨ä½ çš„ä¸»ç³»ç»Ÿä¸­é›†æˆå…³é”®ç‚¹æ£€æµ‹çš„ç¤ºä¾‹ä»£ç 

# 1. å¯¼å…¥å¿…è¦çš„æ¨¡å—
from landmarks.integrate_with_main_system import EnhancedGraspSystem

# 2. åˆå§‹åŒ–å¢å¼ºæŠ“å–ç³»ç»Ÿ
grasp_system = EnhancedGraspSystem(
    landmark_model_path='models/best_fish_landmark_model.pth',
    device='cuda'
)

# 3. åœ¨ä½ çš„ä¸»å¾ªç¯ä¸­ä½¿ç”¨
def enhanced_detect_and_grasp(self, color_image, depth_image, bbox):
    """å¢å¼ºçš„æ£€æµ‹å’ŒæŠ“å–å‡½æ•°"""
    
    # ä½¿ç”¨å…³é”®ç‚¹æ£€æµ‹è®¡ç®—ç²¾ç¡®æŠ“å–ç‚¹
    grasp_point, info = grasp_system.detect_and_calculate_grasp_point(
        rgb_image=color_image,
        depth_image=depth_image,
        bbox=bbox
    )
    
    # å¯è§†åŒ–ç»“æœ
    vis_image = grasp_system.visualize_enhanced_detection(
        rgb_image=color_image,
        grasp_point=grasp_point,
        info=info,
        bbox=bbox
    )
    
    # æ˜¾ç¤ºç»“æœ
    # æ£€æŸ¥æ˜¯å¦æ”¯æŒGUIæ˜¾ç¤º
    try:
        cv2.imshow('Enhanced Detection', vis_image)
    except cv2.error as e:
        if "not implemented" in str(e).lower():
            print("âš ï¸  OpenCV GUIä¸æ”¯æŒï¼Œè·³è¿‡å›¾åƒæ˜¾ç¤º")
        else:
            raise e
    
    # æ‰“å°æ£€æµ‹ä¿¡æ¯
    print(f"æŠ“å–æ–¹æ³•: {info['method']}")
    print(f"ç½®ä¿¡åº¦: {info['confidence']:.2f}")
    print(f"å¤„ç†æ—¶é—´: {info['processing_time']*1000:.1f}ms")
    
    # å¦‚æœæ£€æµ‹æˆåŠŸï¼Œä½¿ç”¨ç²¾ç¡®çš„æŠ“å–ç‚¹
    if info['confidence'] > 0.5:
        # å°†2DæŠ“å–ç‚¹è½¬æ¢ä¸º3Dç‚¹äº‘ä¸­çš„æŠ“å–ç‚¹
        # è¿™é‡Œéœ€è¦ç»“åˆæ·±åº¦ä¿¡æ¯
        return grasp_point, True
    else:
        # ä½¿ç”¨å¤‡é€‰æ–¹æ¡ˆ
        return None, False

# 4. é…ç½®æŠ“å–ç­–ç•¥
grasp_system.set_grasp_strategy('hybrid')  # æ··åˆç­–ç•¥
grasp_system.set_confidence_threshold(0.7)  # ç½®ä¿¡åº¦é˜ˆå€¼

# 5. è·å–æ€§èƒ½ç»Ÿè®¡
stats = grasp_system.get_performance_stats()
print(f"å¹³å‡FPS: {stats['landmark_detector']['avg_fps']:.1f}")
'''
    
    return example_code


def main():
    """ä¸»å‡½æ•° - æ¼”ç¤ºé›†æˆåŠŸèƒ½"""
    
    print("="*60)
    print("ğŸ”— é±¼ä½“å…³é”®ç‚¹æ£€æµ‹é›†æˆæ¼”ç¤º")
    print("="*60)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹æ–‡ä»¶
    model_path = "models/best_fish_landmark_model.pth"
    if not os.path.exists(model_path):
        print(f"âŒ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
        print("è¯·å…ˆè®­ç»ƒæ¨¡å‹æˆ–æŒ‡å®šæ­£ç¡®çš„æ¨¡å‹è·¯å¾„")
        return
    
    # åˆ›å»ºé›†æˆç¤ºä¾‹ä»£ç 
    example_code = create_integration_example()
    
    # ä¿å­˜ç¤ºä¾‹ä»£ç åˆ°æ–‡ä»¶
    example_file = "integration_example.py"
    with open(example_file, 'w', encoding='utf-8') as f:
        f.write(example_code)
    
    print(f"âœ… é›†æˆç¤ºä¾‹ä»£ç å·²ä¿å­˜åˆ°: {example_file}")
    print("\nğŸ“‹ é›†æˆæ­¥éª¤:")
    print("1. è®­ç»ƒå…³é”®ç‚¹æ£€æµ‹æ¨¡å‹")
    print("2. å°† EnhancedGraspSystem é›†æˆåˆ°ä½ çš„ä¸»ç³»ç»Ÿä¸­")
    print("3. æ›¿æ¢åŸæœ‰çš„æŠ“å–ç‚¹è®¡ç®—é€»è¾‘")
    print("4. é…ç½®æŠ“å–ç­–ç•¥å’Œç½®ä¿¡åº¦é˜ˆå€¼")
    print("5. æµ‹è¯•å’Œè°ƒä¼˜")
    
    print(f"\nğŸ’¡ æŸ¥çœ‹ {example_file} äº†è§£è¯¦ç»†çš„é›†æˆä»£ç ç¤ºä¾‹")


if __name__ == "__main__":
    main()



