# 鱿鱼智能抓取系统

<div align="center">

**基于AI视觉与机器人控制的鱿鱼自动化分拣系统**

</div>

## 📋 项目概述

本项目是一个完整的AI驱动的鱿鱼自动化抓取与分拣系统，结合了深度学习视觉技术、3D点云处理和机器人控制。系统使用吸盘末端执行器实现对水产品（鱿鱼）的精准抓取，并完成自动化分拣任务。

### 🎯 核心目标

- **高精度检测**：在复杂水产环境中准确识别和定位鱿鱼
- **智能抓取**：预测最佳抓取点和抓取姿态
- **自动化流程**：从检测、分割、抓取到分拣的全自动化流水线
- **鲁棒性**：适应脏水、不同颜色和光照变化等真实工业场景

## ✨ 核心功能

### 1. 鱼类检测 (Fish Detection)
- **技术栈**：YOLOv8
- **功能**：实时检测视野内的鱿鱼目标，输出边界框和置信度
- **特性**：
  - 支持增量训练和难例挖掘
  - 硬负样本挖掘提升检测鲁棒性
  - 实时检测速度优化

### 2. 实例分割 (Instance Segmentation)
- **技术栈**：SAM (Segment Anything Model)
- **功能**：基于检测结果生成精确的鱼体轮廓掩码
- **特性**：
  - 像素级精确分割
  - 支持重叠目标分离
  - 自动过滤噪声点

### 3. 抓取点预测 (Grasp Point Prediction)
- **技术栈**：EfficientNet
- **功能**：预测鱿鱼表面最优的吸盘抓取位置
- **特性**：
  - 基于鱼体形状和纹理特征
  - 输出2D抓取点坐标
  - 考虑吸盘物理约束

### 4. 姿态估计 (Pose Estimation)
- **技术栈**：PCA (主成分分析)
- **功能**：计算鱼体主轴方向，确定抓取角度
- **特性**：
  - 基于分割掩码的几何分析
  - 鲁棒的方向估计
  - 与机器人坐标系对齐

### 5. 3D点云处理
- **技术栈**：RealSense深度相机 + Open3D
- **功能**：将2D检测结果映射到3D空间
- **特性**：
  - 手眼标定系统
  - 深度滤波和离群点去除
  - 相机-机器人坐标转换

### 6. 机器人控制
- **硬件**：Jaka机械臂 + 吸盘末端执行器
- **功能**：执行抓取和放置动作
- **特性**：
  - 动态抓取策略
  - 静态抓取策略
  - 轨迹规划与碰撞避免

## 🏗️ 系统架构

```
┌─────────────────┐
│  RealSense相机  │
└────────┬────────┘
         │
         ▼
┌─────────────────┐     ┌──────────────────┐
│   YOLO检测      │────▶│   SAM分割        │
│  (YOLOv8)       │     │  (SAM Model)     │
└─────────────────┘     └────────┬─────────┘
                                 │
         ┌───────────────────────┴───────────────────┐
         │                                           │
         ▼                                           ▼
┌─────────────────┐                        ┌─────────────────┐
│  抓取点预测     │                        │  姿态估计       │
│ (EfficientNet)  │                        │    (PCA)        │
└────────┬────────┘                        └────────┬────────┘
         │                                          │
         └──────────────┬───────────────────────────┘
                        │
                        ▼
                ┌───────────────┐
                │  3D坐标转换   │
                │ (点云处理)    │
                └───────┬───────┘
                        │
                        ▼
                ┌───────────────┐
                │  机器人控制   │
                │  (Jaka臂)     │
                └───────────────┘
```

## 📊 工作流程

1. **初始化**：启动相机、加载模型、连接机器人
2. **场景感知**：获取RGB-D图像
3. **目标检测**：YOLO识别所有鱿鱼位置
4. **实例分割**：SAM生成每条鱼的精确掩码
5. **特征提取**：
   - EfficientNet预测抓取点
   - PCA计算鱼体方向
6. **3D映射**：将2D结果转换为3D机器人坐标
7. **运动规划**：计算抓取轨迹
8. **执行抓取**：机器人移动到目标位置并激活吸盘
9. **放置分拣**：将鱼放入指定容器位置

## 🚀 已完成功能

- ✅ 完整的鱼类检测pipeline（YOLO训练、测试、部署）
- ✅ SAM集成的实例分割系统
- ✅ 基于EfficientNet的抓取点预测模型
- ✅ 基于PCA的鱼体方向估计
- ✅ RealSense相机手眼标定系统
- ✅ 3D点云处理与坐标转换
- ✅ 单吸盘动态抓取策略
- ✅ 单吸盘静态抓取策略
- ✅ 实时可视化系统
- ✅ 硬负样本挖掘训练策略

## 🔧 待改进方向

### 1. 检测模块增强
- [ ] **数据集扩充**：收集更多样化的训练数据
  - 脏水、浑浊水质环境
  - 不同颜色的鱿鱼品种
  - 不同光照条件（强光、弱光、侧光）
  - 鱼体重叠、遮挡场景
- [ ] **模型优化**：
  - 数据增强策略（色彩抖动、模糊、噪声）
  - 域自适应技术
  - 小目标检测优化

### 2. 分割模块改进
- [ ] **更鲁棒的分割方案**：
  - 针对鱼体特征微调SAM模型
  - 集成边缘检测算法
  - 后处理优化（形态学操作、轮廓平滑）
  - 处理部分遮挡和重叠情况
- [ ] **形状完整性检测**：
  - 验证分割结果的完整性
  - 检测异常形状并重新分割

### 3. 双吸盘支持
- [ ] **双点抓取算法**：
  - 预测两个最佳抓取点位置
  - 计算两点间距离和夹角约束
  - 确保双点均在鱼体稳定区域
- [ ] **硬件集成**：
  - 双吸盘末端执行器控制
  - 独立气压控制系统
  - 抓取力反馈检测
- [ ] **策略优化**：
  - 针对不同大小鱼体的双点选择
  - 提高大型鱿鱼的抓取成功率

### 4. 智能分拣系统
- [ ] **有序放置算法**：
  - 容器内位置规划（行列布局）
  - 实时计算下一个可用放置位置
  - 避免鱼体相互重叠
- [ ] **分拣策略**：
  - 按大小分类（大、中、小）
  - 按质量分级（完整度、新鲜度）
  - 优化排列密度，提高空间利用率
- [ ] **多容器管理**：
  - 支持多个目标容器
  - 容器满载检测
  - 自动切换容器

### 5. 系统性能优化
- [ ] 推理速度优化（模型量化、TensorRT加速）
- [ ] 多线程并行处理
- [ ] 降低延迟，提高抓取节拍
- [ ] 异常处理和自动恢复机制

## 📁 项目结构

```
.
├── detection/              # 鱼类检测模块
│   ├── train_yolo.py      # YOLO训练脚本
│   ├── test_yolo.py       # 检测测试
│   ├── prepare_yolo_dataset.py
│   └── hard_negative_mining.py
├── landmarks/              # 关键点检测（实验性）
│   └── fish_landmark_detector.py
├── hand_eye_calibrate/     # 手眼标定系统
│   ├── hand_eye_calibrate.py
│   ├── camera_intrinsics.json
│   └── collect_data/
├── groundingdino/          # GroundingDINO配置
├── seg.py                  # 分割模块
├── squid_segment_sam.py    # SAM集成
├── dyna_grasp.py          # 动态抓取策略
├── static_grasp.py        # 静态抓取策略
├── mask_to_3d.py          # 2D到3D映射
├── point_cloud_utils.py   # 点云处理工具
├── PositionSolver.py      # 坐标求解器
├── realsense_capture.py   # 相机采集
└── util.py                # 通用工具函数
```

## 🛠️ 环境依赖

### 硬件要求
- Intel RealSense深度相机（D435/D455）
- Jaka协作机械臂
- 真空吸盘末端执行器
- NVIDIA GPU（推荐RTX 3060或更高）

### 软件环境
- Python 3.8+
- PyTorch 2.0+
- Ultralytics (YOLOv8)
- Segment Anything (SAM)
- Open3D
- OpenCV
- pyrealsense2

## 🚀 快速开始

### 1. 安装依赖
```bash
pip install -r requirements.txt
```

### 2. 手眼标定
```bash
cd hand_eye_calibrate
python hand_eye_calibrate.py
```

### 3. 运行演示
```bash
# 单目标静态抓取
bash run_demo_single_static.sh

# 单目标动态抓取（AI预测）
bash run_demo_single_ai.sh

# 动态多目标抓取
bash run_demo_dyna_ai.sh
```

### 4. 训练检测模型
```bash
cd detection
bash start_incremental_training.sh
```

## 📊 性能指标

| 指标 | 数值 |
|------|------|
| 检测精度 (mAP@0.5) | ~85% |
| 检测速度 | 30+ FPS |
| 抓取成功率 | ~80% |
| 平均抓取周期 | ~8秒 |

## 🤝 贡献

欢迎提交Issue和Pull Request来改进本项目！

## 📄 许可证

[添加适当的许可证信息]

## 📞 联系方式

[添加联系方式]

---

**注**：本项目处于持续开发中，部分功能仍在优化。
