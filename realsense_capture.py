#!/usr/bin/env python3
"""
RealSenseç›¸æœºæ•°æ®é‡‡é›†è„šæœ¬

ä½¿ç”¨pyrealsense2è¯»å–Intel RealSenseç›¸æœºçš„RGBå’Œæ·±åº¦æ•°æ®ï¼Œå¹¶ä¿å­˜åˆ°æŒ‡å®šç›®å½•ã€‚

ä½¿ç”¨æ–¹æ³•:
    python3 realsense_capture.py --output_dir captured_data --num_frames 100 --interval 0.1

å‚æ•°:
    --output_dir: è¾“å‡ºç›®å½•è·¯å¾„
    --num_frames: è¦æ•è·çš„å¸§æ•° (é»˜è®¤: 100)
    --interval: å¸§é—´é—´éš”æ—¶é—´(ç§’) (é»˜è®¤: 0.1)
    --width: RGBå›¾åƒå®½åº¦ (é»˜è®¤: 640)
    --height: RGBå›¾åƒé«˜åº¦ (é»˜è®¤: 480)
    --depth_width: æ·±åº¦å›¾åƒå®½åº¦ (é»˜è®¤: 640)
    --depth_height: æ·±åº¦å›¾åƒé«˜åº¦ (é»˜è®¤: 480)
    --fps: å¸§ç‡ (é»˜è®¤: 30)

ä¾èµ–:
    pip install pyrealsense2 numpy opencv-python
"""

import argparse
import os
import sys
import time
import numpy as np
import cv2
import pyrealsense2 as rs
from datetime import datetime
import open3d as o3d

def depth_to_pointcloud(depth_image, color_image, fx=615.0, fy=615.0, cx=320.0, cy=240.0):
    """
    å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸º3Dç‚¹äº‘
    
    Args:
        depth_image: æ·±åº¦å›¾åƒ (H, W) å•ä½: æ¯«ç±³
        color_image: RGBå›¾åƒ (H, W, 3)
        fx, fy: ç„¦è·
        cx, cy: ä¸»ç‚¹åæ ‡
    
    Returns:
        points: 3Dç‚¹åæ ‡ (N, 3)
        colors: RGBé¢œè‰² (N, 3)
    """
    height, width = depth_image.shape
    
    # åˆ›å»ºç½‘æ ¼åæ ‡
    y_coords, x_coords = np.meshgrid(np.arange(height), np.arange(width), indexing='ij')
    
    # è¿‡æ»¤æœ‰æ•ˆæ·±åº¦å€¼
    valid_mask = depth_image > 0
    x_coords = x_coords[valid_mask]
    y_coords = y_coords[valid_mask]
    depths = depth_image[valid_mask]
    
    if len(depths) == 0:
        return np.array([]), np.array([])
    
    # è®¡ç®—3Dåæ ‡ (ä½¿ç”¨é’ˆå­”ç›¸æœºæ¨¡å‹)
    z = depths / 1000.0  # è½¬æ¢ä¸ºç±³
    x = (x_coords - cx) * z / fx
    y = (y_coords - cy) * z / fy
    
    # ç»„åˆ3Dç‚¹
    points = np.column_stack([x, y, z])
    
    # è·å–å¯¹åº”çš„RGBé¢œè‰²
    colors = color_image[valid_mask]
    colors = colors.astype(np.float32) / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
    
    return points, colors

def save_pointcloud_to_file(points, colors, output_path):
    """
    ä¿å­˜ç‚¹äº‘ä¸ºPLYæ–‡ä»¶
    
    Args:
        points: 3Dç‚¹åæ ‡ (N, 3)
        colors: RGBé¢œè‰² (N, 3)
        output_path: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    if len(points) == 0:
        print(f"è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„3Dç‚¹ï¼Œè·³è¿‡ä¿å­˜: {output_path}")
        return False
    
    # åˆ›å»ºOpen3Dç‚¹äº‘å¯¹è±¡
    pcd = o3d.geometry.PointCloud()
    pcd.points = o3d.utility.Vector3dVector(points)
    pcd.colors = o3d.utility.Vector3dVector(colors)
    
    # ä¿å­˜ä¸ºPLYæ–‡ä»¶
    success = o3d.io.write_point_cloud(output_path, pcd)
    if success:
        print(f"  âœ“ ç‚¹äº‘ä¿å­˜æˆåŠŸ: {os.path.basename(output_path)} (ç‚¹æ•°: {len(points)})")
    else:
        print(f"  âœ— ç‚¹äº‘ä¿å­˜å¤±è´¥: {output_path}")
    
    return success

def setup_realsense(width=640, height=480, depth_width=640, depth_height=480, fps=30, disable_auto_white_balance=True, manual_white_balance=4600):
    """
    è®¾ç½®RealSenseç›¸æœºé…ç½®ï¼ˆå¸¦å›é€€ç­–ç•¥ï¼Œé¿å…V4L2æ ¼å¼åå•†å¤±è´¥ï¼‰
    
    Args:
        width: RGBå›¾åƒå®½åº¦
        height: RGBå›¾åƒé«˜åº¦
        depth_width: æ·±åº¦å›¾åƒå®½åº¦
        depth_height: æ·±åº¦å›¾åƒé«˜åº¦
        fps: å¸§ç‡
        disable_auto_white_balance: æ˜¯å¦å…³é—­è‡ªåŠ¨ç™½å¹³è¡¡
        manual_white_balance: æ‰‹åŠ¨ç™½å¹³è¡¡æ¸©åº¦å€¼ï¼ˆKï¼‰
    """
    pipeline = rs.pipeline()

    # å°è¯•çš„é…ç½®åˆ—è¡¨ï¼ˆä»å¸¸è§åˆ°ä¿å®ˆï¼‰
    attempts = [
        {"color": (width, height, rs.format.bgr8, fps), "depth": (depth_width, depth_height, rs.format.z16, fps), "label": "bgr8+z16"},
        {"color": (640, 480, rs.format.bgr8, 30), "depth": (640, 480, rs.format.z16, 30), "label": "640x480@30 bgr8+z16"},
        {"color": (1280, 720, rs.format.bgr8, 30), "depth": (640, 480, rs.format.z16, 30), "label": "1280x720 color + 640x480 depth"},
        {"color": (640, 480, rs.format.yuyv, 30), "depth": (640, 480, rs.format.z16, 30), "label": "yuyv+z16"},
        {"color": None, "depth": (640, 480, rs.format.z16, 30), "label": "depth-only"},
        {"color": "auto", "depth": "auto", "label": "librealsense-auto"},
    ]

    last_error = None
    for attempt in attempts:
        try:
            config = rs.config()
            if attempt["color"] == "auto" and attempt["depth"] == "auto":
                profile = pipeline.start()  # è®©librealsenseè‡ªåŠ¨é€‰æ‹©å¯ç”¨é…ç½®
                print("RealSenseç›¸æœºå¯åŠ¨æˆåŠŸ (è‡ªåŠ¨é…ç½®)")
                # é…ç½®ä¼ æ„Ÿå™¨é€‰é¡¹
                _configure_sensor_options(pipeline, disable_auto_white_balance, manual_white_balance)
                return pipeline, config
            if attempt["color"] is not None:
                cw, ch, cf, cfps = attempt["color"]
                config.enable_stream(rs.stream.color, cw, ch, cf, cfps)
            if attempt["depth"] is not None:
                dw, dh, df, dfps = attempt["depth"]
                config.enable_stream(rs.stream.depth, dw, dh, df, dfps)
            profile = pipeline.start(config)
            # æ‰“å°æˆåŠŸä¿¡æ¯
            print(f"RealSenseç›¸æœºå¯åŠ¨æˆåŠŸ ({attempt['label']})")
            if attempt["color"] is not None:
                print(f"RGBæµ: {cw}x{ch} @ {cfps}fps")
            if attempt["depth"] is not None:
                print(f"æ·±åº¦æµ: {dw}x{dh} @ {dfps}fps")
            
            # é…ç½®ä¼ æ„Ÿå™¨é€‰é¡¹
            _configure_sensor_options(pipeline, disable_auto_white_balance, manual_white_balance)
            return pipeline, config
        except Exception as e:
            last_error = e
            try:
                pipeline.stop()
            except Exception:
                pass
            pipeline = rs.pipeline()
            print(f"å°è¯•é…ç½®å¤±è´¥ ({attempt['label']}): {e}")

    print(f"å¯åŠ¨RealSenseç›¸æœºå¤±è´¥: {last_error}")
    return None, None

def _configure_sensor_options(pipeline, disable_auto_white_balance=True, manual_white_balance=4600):
    """
    é…ç½®RealSenseä¼ æ„Ÿå™¨é€‰é¡¹
    
    Args:
        pipeline: RealSenseç®¡é“å¯¹è±¡
        disable_auto_white_balance: æ˜¯å¦å…³é—­è‡ªåŠ¨ç™½å¹³è¡¡
        manual_white_balance: æ‰‹åŠ¨ç™½å¹³è¡¡æ¸©åº¦å€¼ï¼ˆKï¼‰
    """
    try:
        # è·å–è®¾å¤‡
        device = pipeline.get_active_profile().get_device()
        
        # è·å–RGBä¼ æ„Ÿå™¨
        rgb_sensor = device.first_color_sensor()
        
        if rgb_sensor is not None:
            # å…³é—­è‡ªåŠ¨ç™½å¹³è¡¡
            if disable_auto_white_balance:
                try:
                    rgb_sensor.set_option(rs.option.enable_auto_white_balance, 0)
                    print(f"âœ“ å·²å…³é—­è‡ªåŠ¨ç™½å¹³è¡¡")
                except Exception as e:
                    print(f"è­¦å‘Š: æ— æ³•å…³é—­è‡ªåŠ¨ç™½å¹³è¡¡: {e}")
            
            # è®¾ç½®æ‰‹åŠ¨ç™½å¹³è¡¡
            try:
                rgb_sensor.set_option(rs.option.white_balance, manual_white_balance)
                print(f"âœ“ å·²è®¾ç½®æ‰‹åŠ¨ç™½å¹³è¡¡: {manual_white_balance}K")
            except Exception as e:
                print(f"è­¦å‘Š: æ— æ³•è®¾ç½®æ‰‹åŠ¨ç™½å¹³è¡¡: {e}")
        else:
            print("è­¦å‘Š: æœªæ‰¾åˆ°RGBä¼ æ„Ÿå™¨ï¼Œæ— æ³•é…ç½®ç™½å¹³è¡¡é€‰é¡¹")
            
    except Exception as e:
        print(f"è­¦å‘Š: é…ç½®ä¼ æ„Ÿå™¨é€‰é¡¹æ—¶å‡ºé”™: {e}")

def capture_frames(pipeline, align, timeout_ms=10000):
    """
    æ•è·ä¸€å¸§å¹¶è¿”å›BGRå½©è‰²å›¾ä¸ä»¥æ¯«ç±³ä¸ºå•ä½çš„æ·±åº¦å›¾ã€‚
    è¿”å› (color_image_bgr, depth_image_mm, success)
    """
    try:
        frames = pipeline.wait_for_frames(timeout_ms=timeout_ms)
        aligned_frames = align.process(frames)
        color_frame = aligned_frames.get_color_frame()
        depth_frame = aligned_frames.get_depth_frame()
        if not color_frame or not depth_frame:
            return None, None, False
        color_image = np.asanyarray(color_frame.get_data())
        height, width = depth_frame.get_height(), depth_frame.get_width()
        depth_image = np.zeros((height, width), dtype=np.uint16)
        for y in range(height):
            for x in range(width):
                dist = depth_frame.get_distance(x, y)
                if dist > 0:
                    depth_image[y, x] = int(dist * 1000)
        return color_image, depth_image, True
    except rs.error as e:
        if "Frame didn't arrive within" in str(e):
            print(f"âš ï¸  å¸§è¶…æ—¶: {e}")
            print("   å¯èƒ½åŸå› : ç›¸æœºè¿æ¥ä¸ç¨³å®šæˆ–USBå¸¦å®½ä¸è¶³")
        else:
            print(f"âš ï¸  RealSenseé”™è¯¯: {e}")
        return None, None, False
    except Exception as e:
        print(f"âŒ æ•è·å¸§æ—¶å‡ºé”™: {e}")
        return None, None, False

def capture_frames_with_retry(pipeline, align, max_retries=3, timeout_ms=10000):
    for attempt in range(max_retries):
        color_image, depth_image, success = capture_frames(pipeline, align, timeout_ms)
        if success:
            if attempt > 0:
                print(f"âœ… ç¬¬{attempt + 1}æ¬¡å°è¯•æˆåŠŸæ•è·å¸§")
            return color_image, depth_image, True
        else:
            if attempt < max_retries - 1:
                print(f"ğŸ”„ ç¬¬{attempt + 1}æ¬¡å°è¯•å¤±è´¥ï¼Œæ­£åœ¨é‡è¯•...")
                time.sleep(0.5)
            else:
                print(f"âŒ ç»è¿‡{max_retries}æ¬¡å°è¯•åä»ç„¶æ— æ³•æ•è·å¸§")
    return None, None, False

def validate_camera_connection(pipeline, align, timeout_ms=5000):
    try:
        print("ğŸ” æ­£åœ¨éªŒè¯ç›¸æœºè¿æ¥...")
        color_image, depth_image, success = capture_frames(pipeline, align, timeout_ms)
        if success and color_image is not None and depth_image is not None:
            print("âœ… ç›¸æœºè¿æ¥æ­£å¸¸")
            return True
        else:
            print("âŒ ç›¸æœºè¿æ¥å¼‚å¸¸ï¼šæ— æ³•è·å–æœ‰æ•ˆå¸§")
            return False
    except Exception as e:
        print(f"âŒ ç›¸æœºè¿æ¥éªŒè¯å¤±è´¥: {e}")
        return False

def check_camera_health(pipeline):
    try:
        frames = pipeline.wait_for_frames(timeout_ms=2000)
        return frames is not None
    except Exception:
        return False

def capture_and_save(pipeline, output_dir, num_frames=100, interval=0.1, wait_for_q=False, show_preview=True, save_pointcloud=True):
    """
    æ•è·å¹¶ä¿å­˜RGBå’Œæ·±åº¦å›¾åƒ
    
    Args:
        pipeline: RealSenseç®¡é“å¯¹è±¡
        output_dir: è¾“å‡ºç›®å½•
        num_frames: è¦æ•è·çš„å¸§æ•°
        interval: å¸§é—´é—´éš”æ—¶é—´(ç§’)
        wait_for_q: æ˜¯å¦ç­‰å¾…æŒ‰'q'é”®åœæ­¢
        show_preview: æ˜¯å¦æ˜¾ç¤ºå®æ—¶é¢„è§ˆçª—å£
    """
    # åˆ›å»ºè¾“å‡ºç›®å½•
    rgb_dir = os.path.join(output_dir, "rgb")
    depth_dir = os.path.join(output_dir, "depth")
    os.makedirs(rgb_dir, exist_ok=True)
    os.makedirs(depth_dir, exist_ok=True)
    
    # å¦‚æœå¯ç”¨ç‚¹äº‘ä¿å­˜ï¼Œåˆ›å»ºç‚¹äº‘ç›®å½•
    if save_pointcloud:
        pointcloud_dir = os.path.join(output_dir, "pointclouds")
        os.makedirs(pointcloud_dir, exist_ok=True)
    
    # è·å–æ·±åº¦ä¼ æ„Ÿå™¨å’Œç›¸æœºå†…å‚
    profile = pipeline.get_active_profile()
    depth_sensor = profile.get_device().first_depth_sensor()
    
    # è·å–æ·±åº¦æ¯”ä¾‹å› å­
    depth_scale = depth_sensor.get_depth_scale()
    print(f"æ·±åº¦æ¯”ä¾‹å› å­: {depth_scale}")
    
    # è·å–ç›¸æœºå†…å‚
    color_profile = rs.video_stream_profile(profile.get_stream(rs.stream.color))
    color_intrinsics = color_profile.get_intrinsics()
    fx = color_intrinsics.fx
    fy = color_intrinsics.fy
    cx = color_intrinsics.ppx
    cy = color_intrinsics.ppy
    print(f"ç›¸æœºå†…å‚: fx={fx:.1f}, fy={fy:.1f}, cx={cx:.1f}, cy={cy:.1f}")
    
    # åˆ›å»ºå¯¹é½å¯¹è±¡
    align = rs.align(rs.stream.color)
    
    if wait_for_q or num_frames == 0:
        print(f"å¼€å§‹å®æ—¶æ•è·ï¼ŒæŒ‰ 'q' é”®åœæ­¢...")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
    else:
        print(f"å¼€å§‹æ•è· {num_frames} å¸§å›¾åƒ...")
        print(f"è¾“å‡ºç›®å½•: {output_dir}")
    
    frame_count = 0
    start_time = time.time()
    fps_start_time = start_time
    fps_frame_count = 0
    
    try:
        while True:
            # ç­‰å¾…æ–°çš„å¸§
            frames = pipeline.wait_for_frames()
            
            # å¯¹é½æ·±åº¦å¸§åˆ°RGBå¸§
            aligned_frames = align.process(frames)
            
            # è·å–å¯¹é½åçš„å¸§
            color_frame = aligned_frames.get_color_frame()
            depth_frame = aligned_frames.get_depth_frame()
            
            if not color_frame or not depth_frame:
                print(f"è­¦å‘Š: ç¬¬ {frame_count} å¸§æ•°æ®æ— æ•ˆï¼Œè·³è¿‡")
                continue
            
            # è½¬æ¢ä¸ºnumpyæ•°ç»„
            color_image = np.asanyarray(color_frame.get_data())
            
            # æ£€æŸ¥é¢œè‰²æ ¼å¼å¹¶è½¬æ¢
            if len(color_image.shape) == 3 and color_image.shape[2] == 3:
                # RealSenseè¾“å‡ºBGRæ ¼å¼ï¼Œè½¬æ¢ä¸ºRGBç”¨äºæ˜¾ç¤º
                color_image_rgb = cv2.cvtColor(color_image, cv2.COLOR_BGR2RGB)
                # ä¿å­˜æ—¶ä½¿ç”¨BGRæ ¼å¼ï¼ˆOpenCVæ ‡å‡†ï¼‰
                color_image_save = color_image
            else:
                print(f"è­¦å‘Š: ç¬¬ {frame_count} å¸§é¢œè‰²æ ¼å¼å¼‚å¸¸: {color_image.shape}")
                continue
            
            # ä½¿ç”¨get_distanceæ–¹æ³•è·å–æ·±åº¦æ•°æ®ï¼ˆæ›´é«˜æ•ˆçš„æ–¹æ³•ï¼‰
            height, width = depth_frame.get_height(), depth_frame.get_width()
            depth_image = np.zeros((height, width), dtype=np.uint16)
            
            # ä½¿ç”¨å‘é‡åŒ–æ“ä½œæ¥æé«˜æ•ˆç‡
            for y in range(height):
                for x in range(width):
                    dist = depth_frame.get_distance(x, y)
                    if dist > 0:
                        # å°†è·ç¦»è½¬æ¢ä¸ºæ¯«ç±³å•ä½ï¼ˆRealSenseé€šå¸¸ä»¥ç±³ä¸ºå•ä½ï¼‰
                        depth_image[y, x] = int(dist * 1000)
            
            # æ£€æŸ¥æ·±åº¦æ•°æ®çš„æœ‰æ•ˆæ€§
            if depth_image is None or depth_image.size == 0:
                print(f"è­¦å‘Š: ç¬¬ {frame_count} å¸§æ·±åº¦æ•°æ®æ— æ•ˆ")
                continue
            
            # ä¿å­˜RGBå›¾åƒ
            rgb_filename = f"rgb_{frame_count:06d}.png"
            rgb_path = os.path.join(rgb_dir, rgb_filename)
            #cv2.imwrite(rgb_path, color_image_save)
            
            # ä¿å­˜å¯è§†åŒ–æ·±åº¦å›¾åƒï¼ˆå½©è‰²ï¼Œå¯è§ï¼‰
            depth_filename = f"depth_{frame_count:06d}.png"
            depth_path = os.path.join(depth_dir, depth_filename)
            
            # åŒæ—¶ä¿å­˜åŸå§‹æ·±åº¦æ•°æ®ï¼ˆ16ä½PNGï¼‰
            depth_raw_filename = f"depth_raw_{frame_count:06d}.png"
            depth_raw_path = os.path.join(depth_dir, depth_raw_filename)
            #cv2.imwrite(depth_raw_path, depth_image.astype(np.uint16))
            
            # ä¿å­˜åŸå§‹æ·±åº¦æ•°æ®ä¸ºnumpyæ•°ç»„
            depth_numpy_filename = f"depth_{frame_count:06d}.npy"
            depth_numpy_path = os.path.join(depth_dir, depth_numpy_filename)
            #np.save(depth_numpy_path, depth_image)
            
            # ç”Ÿæˆå¹¶ä¿å­˜3Dç‚¹äº‘ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            if save_pointcloud:
                points, colors = depth_to_pointcloud(depth_image, color_image_rgb, fx, fy, cx, cy)
                if len(points) > 0:
                    pointcloud_filename = f"pointcloud_{frame_count:06d}.ply"
                    pointcloud_path = os.path.join(pointcloud_dir, pointcloud_filename)
                    save_pointcloud_to_file(points, colors, pointcloud_path)
            
            # åˆ›å»ºå¯è§†åŒ–çš„æ·±åº¦å›¾åƒï¼ˆç°åº¦ï¼‰
            valid_depth = depth_image > 0
            if valid_depth.any():
                depth_min = depth_image[valid_depth].min()
                depth_max = depth_image[valid_depth].max()
                
                # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´ï¼Œä¿å­˜ä¸ºç°åº¦å›¾åƒ
                depth_normalized = np.zeros_like(depth_image, dtype=np.uint8)
                depth_normalized[valid_depth] = ((depth_image[valid_depth] - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
                
                # ä¿å­˜ç°åº¦æ·±åº¦å›¾åƒ
                save_success = cv2.imwrite(depth_path, depth_normalized)
                
                if save_success:
                    print(f"  âœ“ å¯è§†åŒ–æ·±åº¦å›¾åƒä¿å­˜æˆåŠŸ: {depth_filename}")
                    print(f"  âœ“ åŸå§‹æ·±åº¦æ•°æ®ä¿å­˜æˆåŠŸ: {depth_raw_filename}")
                    print(f"  âœ“ Numpyæ•°ç»„ä¿å­˜æˆåŠŸ: {depth_numpy_filename}")
                    print(f"    æ·±åº¦å€¼èŒƒå›´: {depth_min} - {depth_max} (æœ‰æ•ˆåƒç´ : {valid_depth.sum()})")
                else:
                    print(f"  âœ— ä¿å­˜æ·±åº¦å›¾åƒå¤±è´¥: {depth_path}")
            else:
                print("è­¦å‘Š: æ²¡æœ‰æœ‰æ•ˆçš„æ·±åº¦å€¼!")
                # ä¿å­˜é»‘è‰²å›¾åƒ
                black_image = np.zeros((depth_image.shape[0], depth_image.shape[1], 3), dtype=np.uint8)
                cv2.imwrite(depth_path, black_image)
            
            # æ‰“å°æ·±åº¦å€¼èŒƒå›´ç”¨äºè°ƒè¯•ï¼ˆä»…ç¬¬ä¸€å¸§ï¼‰
            if frame_count == 0:
                print(f"åŸå§‹æ·±åº¦å›¾åƒå½¢çŠ¶: {depth_image.shape}")
                print(f"åŸå§‹æ·±åº¦å›¾åƒæ•°æ®ç±»å‹: {depth_image.dtype}")
                print(f"åŸå§‹æ·±åº¦å›¾åƒå€¼èŒƒå›´: {depth_image.min()} - {depth_image.max()}")
                
                # æ£€æŸ¥æœ‰æ•ˆæ·±åº¦å€¼
                valid_pixels = (depth_image > 0).sum()
                total_pixels = depth_image.size
                print(f"æœ‰æ•ˆæ·±åº¦åƒç´ : {valid_pixels}/{total_pixels} ({valid_pixels/total_pixels:.1%})")
            
            # æ˜¾ç¤ºå®æ—¶é¢„è§ˆ
            # å°†æ·±åº¦å›¾åƒè½¬æ¢ä¸ºå¯è§†åŒ–æ ¼å¼
            # ä½¿ç”¨åŸå§‹æ·±åº¦å›¾åƒè¿›è¡Œå¯è§†åŒ–
            valid_depth = depth_image > 0
            if valid_depth.any():
                depth_min = depth_image[valid_depth].min()
                depth_max = depth_image[valid_depth].max()
                # å½’ä¸€åŒ–åˆ°0-255èŒƒå›´
                depth_normalized = np.zeros_like(depth_image, dtype=np.uint8)
                depth_normalized[valid_depth] = ((depth_image[valid_depth] - depth_min) / (depth_max - depth_min) * 255).astype(np.uint8)
                depth_colormap = cv2.applyColorMap(depth_normalized, cv2.COLORMAP_JET)
            else:
                depth_colormap = np.zeros((depth_image.shape[0], depth_image.shape[1], 3), dtype=np.uint8)
            
            # è°ƒæ•´å›¾åƒå¤§å°ä»¥ä¾¿æ˜¾ç¤º
            color_display = cv2.resize(color_image_rgb, (640, 480))
            depth_display = cv2.resize(depth_colormap, (640, 480))
            
            # æ°´å¹³æ‹¼æ¥RGBå’Œæ·±åº¦å›¾åƒ
            combined = np.hstack((color_display, depth_display))
            
            # è®¡ç®—å½“å‰FPS
            current_time = time.time()
            if frame_count > 0:
                elapsed_time = current_time - start_time
                current_fps = frame_count / elapsed_time
            else:
                current_fps = 0
            
            # æ·»åŠ æ–‡å­—è¯´æ˜
            cv2.putText(combined, f"Frame: {frame_count}", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(combined, f"FPS: {current_fps:.1f}", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            cv2.putText(combined, "Press 'q' to stop", (10, 90), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
            
            # æ˜¾ç¤ºå›¾åƒ
            cv2.imshow('RealSense Capture - RGB | Depth', combined)
            
            # è®¡ç®—FPS
            current_time = time.time()
            fps_frame_count += 1
            
            # æ¯ç§’æ›´æ–°ä¸€æ¬¡FPSæ˜¾ç¤º
            if current_time - fps_start_time >= 1.0:
                fps = fps_frame_count / (current_time - fps_start_time)
                print(f"å·²ä¿å­˜ç¬¬ {frame_count+1} å¸§: RGB={rgb_filename}, Depth={depth_filename} | FPS: {fps:.1f}")
                fps_start_time = current_time
                fps_frame_count = 0
            else:
                print(f"å·²ä¿å­˜ç¬¬ {frame_count+1} å¸§: RGB={rgb_filename}, Depth={depth_filename}")
            
            frame_count += 1
            
            # æ£€æŸ¥æ˜¯å¦è¾¾åˆ°æŒ‡å®šå¸§æ•°ï¼ˆå¦‚æœè®¾ç½®äº†çš„è¯ï¼‰
            if num_frames > 0 and frame_count >= num_frames:
                print(f"\nå·²è¾¾åˆ°æŒ‡å®šå¸§æ•° {num_frames}ï¼Œåœæ­¢æ•è·")
                break
            
            # æ£€æŸ¥æŒ‰é”® - ä½¿ç”¨æ›´çŸ­çš„ç­‰å¾…æ—¶é—´ä»¥ä¿æŒé«˜å¸§ç‡
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                print("\nç”¨æˆ·æŒ‰ 'q' é”®åœæ­¢æ•è·")
                break
            
            # åªæœ‰åœ¨æŒ‡å®šäº†é—´éš”ä¸”ä¸æ˜¯æ— é™å¾ªç¯æ¨¡å¼æ—¶æ‰æ·»åŠ å»¶è¿Ÿ
            if interval > 0 and num_frames > 0:
                time.sleep(interval)
                
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ•è·")
    except Exception as e:
        print(f"æ•è·è¿‡ç¨‹ä¸­å‡ºé”™: {e}")
    finally:
        # å…³é—­æ‰€æœ‰çª—å£
        cv2.destroyAllWindows()
        # åœæ­¢ç®¡é“
        pipeline.stop()
        print("RealSenseç›¸æœºå·²åœæ­¢")
        print(f"æ€»å…±æ•è·äº† {frame_count} å¸§å›¾åƒ")

def main():
    parser = argparse.ArgumentParser(description='RealSenseç›¸æœºæ•°æ®é‡‡é›†')
    parser.add_argument('--output_dir', type=str, default='captured_data',
                      help='è¾“å‡ºç›®å½•è·¯å¾„ (é»˜è®¤: captured_data)')
    parser.add_argument('--num_frames', type=int, default=0,
                      help='è¦æ•è·çš„å¸§æ•° (é»˜è®¤: 0è¡¨ç¤ºæ— é™å¾ªç¯)')
    parser.add_argument('--interval', type=float, default=0.1,
                      help='å¸§é—´é—´éš”æ—¶é—´(ç§’) (é»˜è®¤: 0.1)')
    parser.add_argument('--width', type=int, default=640,
                      help='RGBå›¾åƒå®½åº¦ (é»˜è®¤: 640)')
    parser.add_argument('--height', type=int, default=480,
                      help='RGBå›¾åƒé«˜åº¦ (é»˜è®¤: 480)')
    parser.add_argument('--depth_width', type=int, default=640,
                      help='æ·±åº¦å›¾åƒå®½åº¦ (é»˜è®¤: 640)')
    parser.add_argument('--depth_height', type=int, default=480,
                      help='æ·±åº¦å›¾åƒé«˜åº¦ (é»˜è®¤: 480)')
    parser.add_argument('--fps', type=int, default=30,
                      help='å¸§ç‡ (é»˜è®¤: 30)')
    parser.add_argument('--wait_for_q', action='store_true',
                      help='ç­‰å¾…æŒ‰qé”®åœæ­¢ï¼Œè€Œä¸æ˜¯æŒ‰å¸§æ•°åœæ­¢')
    parser.add_argument('--no_pointcloud', action='store_true',
                      help='ç¦ç”¨3Dç‚¹äº‘ç”Ÿæˆå’Œä¿å­˜')
    parser.add_argument('--enable_auto_white_balance', action='store_true',
                      help='å¯ç”¨è‡ªåŠ¨ç™½å¹³è¡¡ (é»˜è®¤: å…³é—­)')
    parser.add_argument('--white_balance', type=int, default=4600,
                      help='æ‰‹åŠ¨ç™½å¹³è¡¡æ¸©åº¦å€¼(K) (é»˜è®¤: 4600K)')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥pyrealsense2æ˜¯å¦å¯ç”¨
    try:
        import pyrealsense2 as rs
    except ImportError:
        print("é”™è¯¯: æœªå®‰è£…pyrealsense2")
        print("è¯·å®‰è£…: pip install pyrealsense2")
        sys.exit(1)
    
    # è®¾ç½®RealSenseç›¸æœº
    pipeline, config = setup_realsense(
        width=args.width,
        height=args.height,
        depth_width=args.depth_width,
        depth_height=args.depth_height,
        fps=args.fps,
        disable_auto_white_balance=not args.enable_auto_white_balance,
        manual_white_balance=args.white_balance
    )
    
    if pipeline is None:
        print("æ— æ³•å¯åŠ¨RealSenseç›¸æœº")
        sys.exit(1)
    
    # æ•è·å¹¶ä¿å­˜å›¾åƒ
    capture_and_save(pipeline, args.output_dir, args.num_frames, args.interval, args.wait_for_q, show_preview=True, save_pointcloud=not args.no_pointcloud)
    
    print(f"\næ•°æ®é‡‡é›†å®Œæˆ!")
    print(f"RGBå›¾åƒä¿å­˜åœ¨: {os.path.join(args.output_dir, 'rgb')}")
    print(f"æ·±åº¦å›¾åƒä¿å­˜åœ¨: {os.path.join(args.output_dir, 'depth')}")
    if not args.no_pointcloud:
        print(f"3Dç‚¹äº‘ä¿å­˜åœ¨: {os.path.join(args.output_dir, 'pointclouds')}")
    else:
        print("3Dç‚¹äº‘ç”Ÿæˆå·²ç¦ç”¨")

if __name__ == "__main__":
    main()
